{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V750sL91P8t8",
        "outputId": "4e990841-7cfd-4b71-b07a-00f051a62928"
      },
      "outputs": [],
      "source": [
        "#Package installation\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install torch, accelerate, bitsandbyte, sentencepiece, pillow\n",
        "!pip install spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "f8b6845302ce4dfc99c921680e335456",
            "16c03b72f9ed412db242d977d4b86cc3",
            "e489d36014a84c249270dc62fa4dc0a3",
            "437057f7a9f94c819b5e39c6dd0e5b3a",
            "92c983d280d94a3296eb557694ffc892",
            "e6908894d5994af2a497113a18e01304",
            "40f08f1e60b8457686814e945424077a",
            "f242f70cb05a42b592edcf1694880168",
            "f4c5d9ba3f924edd8240488ccd458103",
            "9fb4e9b0a21f4c7bae9872b6766a8a6f",
            "d859d94b016d48f482c2a0a5bfd106e6"
          ]
        },
        "id": "tejyJAIvQLoL",
        "outputId": "10846e42-05b1-4511-f627-bde659866429"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoProcessor, MllamaForConditionalGeneration, TextStreamer\n",
        "from PIL import Image\n",
        "import csv\n",
        "# Check if we're running in a Hugging Face Space and if SPACES_ZERO_GPU is enabled\n",
        "IS_SPACES_ZERO = os.environ.get(\"SPACES_ZERO_GPU\", \"0\") == \"1\"\n",
        "IS_SPACE = os.environ.get(\"SPACE_ID\", None) is not None\n",
        "IS_GDRVIE = True\n",
        "\n",
        "# Determine the device (GPU if available, else CPU)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LOW_MEMORY = os.getenv(\"LOW_MEMORY\", \"0\") == \"1\"\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Low memory mode: {LOW_MEMORY}\")\n",
        "\n",
        "# Get Hugging Face token from environment variables\n",
        "HF_TOKEN = os.environ.get('HF_TOKEN')\n",
        "\n",
        "# Define the model name\n",
        "model_name = \"Llama-3.2-11B-Vision-Instruct\"\n",
        "if IS_GDRVIE:\n",
        "    # Define the path to the model directory in your Google Drive\n",
        "    model_path = \"/content/drive/MyDrive/models/\" + model_name\n",
        "    model = MllamaForConditionalGeneration.from_pretrained(\n",
        "        model_path,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    processor = AutoProcessor.from_pretrained(model_path)\n",
        "else:\n",
        "    model_name = \"ruslanmv/\" + model_name\n",
        "    model = MllamaForConditionalGeneration.from_pretrained(\n",
        "        model_name,\n",
        "        use_auth_token=HF_TOKEN,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    processor = AutoProcessor.from_pretrained(model_name, use_auth_token=HF_TOKEN)\n",
        "\n",
        "\n",
        "\n",
        "# Tie the model weights to ensure the model is properly loaded\n",
        "if hasattr(model, \"tie_weights\"):\n",
        "    model.tie_weights()\n",
        "\n",
        "example = '''Table 1:\n",
        "header1,header2,header3\n",
        "value1,value2,value3\n",
        "\n",
        "Table 2:\n",
        "header1,header2,header3\n",
        "value1,value2,value3\n",
        "'''\n",
        "\n",
        "prompt_message = \"\"\"Please extract all tables from the image and generate CSV files.\n",
        "Each table should be separated using the format table_n.csv, where n is the table number.\n",
        "You must use CSV format with commas as the delimiter. Do not use markdown format. Ensure you use the original table headers and content from the image.\n",
        "Only answer with the CSV content. Dont explain the tables.\n",
        "An example of the formatting output is as follows:\n",
        "\"\"\" + example\n",
        "\n",
        "\n",
        "# Stream LLM response generator\n",
        "def stream_response(inputs):\n",
        "    streamer = TextStreamer(tokenizer=processor.tokenizer)\n",
        "    for token in model.generate(**inputs, max_new_tokens=2000, do_sample=True, streamer=streamer):\n",
        "        yield processor.decode(token, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "# Predict function for Gradio app\n",
        "def predict(message, image):\n",
        "    # Prepare the input messages\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\"},  # Specify that an image is provided\n",
        "            {\"type\": \"text\", \"text\": message}  # Add the user-provided text input\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    # Create the input text using the processor's chat template\n",
        "    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "    # Process the inputs and move to the appropriate device\n",
        "    inputs = processor(image, input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Return a streaming generator of responses\n",
        "    full_response = \"\"\n",
        "    for response in stream_response(inputs):\n",
        "       # print(response, end=\"\", flush=True)  # Print each part of the response as it's generated\n",
        "        full_response += response\n",
        "    return extract_and_save_tables(full_response)\n",
        "\n",
        "# Extract tables and save them to CSV\n",
        "files_list = []\n",
        "\n",
        "def clean_full_response(full_response):\n",
        "    \"\"\"Cleans the full response by removing the prompt input before the tables.\"\"\"\n",
        "    # The part of the prompt input to remove\n",
        "    message_to_remove = prompt_message\n",
        "    # Remove the message and return only the tables\n",
        "    return full_response.replace(message_to_remove, \"\").strip()\n",
        "\n",
        "def extract_and_save_tables(full_response):\n",
        "    \"\"\"Extracts CSV tables from the cleaned_response string and saves them as separate files.\"\"\"\n",
        "    cleaned_response = clean_full_response(full_response)\n",
        "    files_list = []  # Initialize the list of file names\n",
        "    tables = cleaned_response.split(\"Table \")  # Split the response by table sections\n",
        "\n",
        "    for i, table in enumerate(tables[1:], start=1):  # Start with index 1 for \"Table 1\"\n",
        "        table_name = f\"table_{i}.csv\"  # File name for the current table\n",
        "        rows = table.strip().splitlines()[1:]  # Remove \"Table n:\" line and split the table into rows\n",
        "        rows = [row.replace('\"', '').split(\",\") for row in rows if row.strip()]  # Clean and split by commas\n",
        "\n",
        "        # Save the table as a CSV file\n",
        "        with open(table_name, mode=\"w\", newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerows(rows)\n",
        "\n",
        "        files_list.append(table_name)  # Append the saved file to the list\n",
        "\n",
        "    return files_list\n",
        "\n",
        "\n",
        "# Gradio interface\n",
        "def gradio_app():\n",
        "    def process_image(image):\n",
        "        message = prompt_message\n",
        "        files = predict(message, image)\n",
        "        return \"Tables extracted and saved as CSV files.\", files\n",
        "    # Input components\n",
        "    image_input = gr.Image(type=\"pil\", label=\"Upload Image\")\n",
        "\n",
        "    #message_input = gr.Textbox(lines=2, placeholder=\"Enter your message\", value=message)\n",
        "    output_text = gr.Textbox(label=\"Extraction Status\")\n",
        "    file_output = gr.File(label=\"Download CSV files\")\n",
        "\n",
        "    # Gradio interface\n",
        "    iface = gr.Interface(\n",
        "        fn=process_image,\n",
        "        inputs=[image_input],\n",
        "        outputs=[output_text, file_output],\n",
        "        title=\"Table Extractor and CSV Converter\",\n",
        "        description=\"Upload an image to extract tables and download CSV files.\",\n",
        "        allow_flagging=\"never\"\n",
        "    )\n",
        "\n",
        "    iface.launch(debug=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_zvfDX6eg_3"
      },
      "source": [
        "## WebaApp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2AQ-s6Xeegvw",
        "outputId": "08b9bd59-2d57-4ef6-8d86-a73a2af74a1e"
      },
      "outputs": [],
      "source": [
        "# Call the Gradio app function to launch the app\n",
        "gradio_app()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwaqEr9KQihr"
      },
      "source": [
        "## Testing Zone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vIiZil7cSpjJ"
      },
      "outputs": [],
      "source": [
        "# Predict function for Gradio app\n",
        "def predict(message, image):\n",
        "    # Prepare the input messages\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\"},  # Specify that an image is provided\n",
        "            {\"type\": \"text\", \"text\": message}  # Add the user-provided text input\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    # Create the input text using the processor's chat template\n",
        "    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "    # Process the inputs and move to the appropriate device\n",
        "    inputs = processor(image, input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Return a streaming generator of responses\n",
        "    full_response = \"\"\n",
        "    for response in stream_response(inputs):\n",
        "        full_response += response\n",
        "    return full_response\n",
        "    #return extract_and_save_tables(full_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bKF88NAQPm0",
        "outputId": "25fdd4e1-66a5-42cc-f8c7-f5d78b0117bd"
      },
      "outputs": [],
      "source": [
        "# prompt: Can you create a python code that takes the page_1.png file and pass the message \"Please extract the first table in csv format of the image\" and also display the results in streaming, such we can see how is generated\n",
        "from PIL import Image\n",
        "# Assuming 'page_1.png' is in the current directory or you provide the correct path\n",
        "image = Image.open(\"page_0.png\")\n",
        "\n",
        "# Call the predict function with the image and message, capturing the streaming output\n",
        "full_response = \"\"\n",
        "for response in predict(prompt_message, image):\n",
        "  print(response, end=\"\", flush=True)  # Print each part of the response as it's generated\n",
        "  full_response += response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "MswAkuTjUQcd",
        "outputId": "69014426-8a8b-426b-93a6-97c2acf07e13"
      },
      "outputs": [],
      "source": [
        "full_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXMfJXpnXlQR",
        "outputId": "8baa87ff-5c3b-4071-cb38-b79068bc669c"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "def clean_full_response(full_response):\n",
        "    \"\"\"Cleans the full response by removing the prompt input before the tables.\"\"\"\n",
        "    # The part of the prompt input to remove\n",
        "    message_to_remove = prompt_message\n",
        "    # Remove the message and return only the tables\n",
        "    return full_response.replace(message_to_remove, \"\").strip()\n",
        "\n",
        "def extract_and_save_tables(full_response):\n",
        "    \"\"\"Extracts CSV tables from the cleaned_response string and saves them as separate files.\"\"\"\n",
        "    cleaned_response = clean_full_response(full_response)\n",
        "    files_list = []  # Initialize the list of file names\n",
        "    tables = cleaned_response.split(\"Table \")  # Split the response by table sections\n",
        "\n",
        "    for i, table in enumerate(tables[1:], start=1):  # Start with index 1 for \"Table 1\"\n",
        "        table_name = f\"table_{i}.csv\"  # File name for the current table\n",
        "        rows = table.strip().splitlines()[1:]  # Remove \"Table n:\" line and split the table into rows\n",
        "        rows = [row.replace('\"', '').split(\",\") for row in rows if row.strip()]  # Clean and split by commas\n",
        "\n",
        "        # Save the table as a CSV file\n",
        "        with open(table_name, mode=\"w\", newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerows(rows)\n",
        "\n",
        "        files_list.append(table_name)  # Append the saved file to the list\n",
        "\n",
        "    return files_list\n",
        "\n",
        "# Example usage\n",
        "\n",
        "files_list = extract_and_save_tables(full_response)\n",
        "print(files_list)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16c03b72f9ed412db242d977d4b86cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6908894d5994af2a497113a18e01304",
            "placeholder": "​",
            "style": "IPY_MODEL_40f08f1e60b8457686814e945424077a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "40f08f1e60b8457686814e945424077a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "437057f7a9f94c819b5e39c6dd0e5b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fb4e9b0a21f4c7bae9872b6766a8a6f",
            "placeholder": "​",
            "style": "IPY_MODEL_d859d94b016d48f482c2a0a5bfd106e6",
            "value": " 5/5 [00:56&lt;00:00,  6.88s/it]"
          }
        },
        "92c983d280d94a3296eb557694ffc892": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fb4e9b0a21f4c7bae9872b6766a8a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d859d94b016d48f482c2a0a5bfd106e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e489d36014a84c249270dc62fa4dc0a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f242f70cb05a42b592edcf1694880168",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4c5d9ba3f924edd8240488ccd458103",
            "value": 5
          }
        },
        "e6908894d5994af2a497113a18e01304": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f242f70cb05a42b592edcf1694880168": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4c5d9ba3f924edd8240488ccd458103": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8b6845302ce4dfc99c921680e335456": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16c03b72f9ed412db242d977d4b86cc3",
              "IPY_MODEL_e489d36014a84c249270dc62fa4dc0a3",
              "IPY_MODEL_437057f7a9f94c819b5e39c6dd0e5b3a"
            ],
            "layout": "IPY_MODEL_92c983d280d94a3296eb557694ffc892"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
