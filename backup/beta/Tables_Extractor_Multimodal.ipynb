{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92sSdpa5A930"
      },
      "source": [
        "# Table Extractor Multimodal\n",
        "The purpose of this program is extract the tables contained in a image or pdf.\n",
        "\n",
        "The pipeline is the follows:\n",
        "- First the program convert the pdf to image\n",
        "- The image is analized by the llm multimodal\n",
        "- It is extracted all the tables in format csv\n",
        "- It is preprocessed the output of the llm into csv and saved all individual tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HkTxEGLAzs9",
        "outputId": "f1d6e85f-97b8-47c0-ca43-a0f62c413333"
      },
      "outputs": [],
      "source": [
        "#Package installation\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install torch, accelerate, bitsandbyte, sentencepiece, pillow\n",
        "!pip install spaces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "5040ec467bbf4a51abb864e017e08684",
            "1955516ec46949d5b0515c5b4486c614",
            "30c78f5f1933496f8e3cb53be3a67a45",
            "c08e1c100fb846949141d0fe5c99c0da",
            "9a80dc7dc36d4ff8bd811cba89b331d5",
            "a8b736b7c75f4c15a32c11319cf32057",
            "d13d46a3a7374ab28aba00937bbe7fc7",
            "9b12c03a02f54719b80ed75f24855e78",
            "1cb0f8ff5c7d486787fd9d9d950d0164",
            "293fcf4e243d4c5c9006205240a93371",
            "9ea28926351443e89b63796f941cfa5c"
          ]
        },
        "id": "Mch4Pz56CUUj",
        "outputId": "8c54d6dc-c45f-4199-acaf-82be409aab46"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoProcessor, MllamaForConditionalGeneration, TextStreamer\n",
        "from PIL import Image\n",
        "\n",
        "# Check if we're running in a Hugging Face Space and if SPACES_ZERO_GPU is enabled\n",
        "IS_SPACES_ZERO = os.environ.get(\"SPACES_ZERO_GPU\", \"0\") == \"1\"\n",
        "IS_SPACE = os.environ.get(\"SPACE_ID\", None) is not None\n",
        "IS_GDRVIE = True\n",
        "\n",
        "# Determine the device (GPU if available, else CPU)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LOW_MEMORY = os.getenv(\"LOW_MEMORY\", \"0\") == \"1\"\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Low memory mode: {LOW_MEMORY}\")\n",
        "\n",
        "# Get Hugging Face token from environment variables\n",
        "HF_TOKEN = os.environ.get('HF_TOKEN')\n",
        "\n",
        "# Define the model name\n",
        "model_name = \"Llama-3.2-11B-Vision-Instruct\"\n",
        "if IS_GDRVIE:\n",
        "    # Define the path to the model directory in your Google Drive\n",
        "    model_path = \"/content/drive/MyDrive/models/\" + model_name\n",
        "    model = MllamaForConditionalGeneration.from_pretrained(\n",
        "        model_path,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    processor = AutoProcessor.from_pretrained(model_path)\n",
        "else:\n",
        "    model_name = \"ruslanmv/\" + model_name\n",
        "    model = MllamaForConditionalGeneration.from_pretrained(\n",
        "        model_name,\n",
        "        use_auth_token=HF_TOKEN,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    processor = AutoProcessor.from_pretrained(model_name, use_auth_token=HF_TOKEN)\n",
        "\n",
        "# Tie the model weights to ensure the model is properly loaded\n",
        "if hasattr(model, \"tie_weights\"):\n",
        "    model.tie_weights()\n",
        "\n",
        "# Stream LLM response generator\n",
        "def stream_response(inputs):\n",
        "    streamer = TextStreamer(tokenizer=processor.tokenizer)\n",
        "    for token in model.generate(**inputs, max_new_tokens=2000, do_sample=True, streamer=streamer):\n",
        "        yield processor.decode(token, skip_special_tokens=True)\n",
        "\n",
        "def predict(message, image):\n",
        "    # Prepare the input messages\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\"},  # Specify that an image is provided\n",
        "            {\"type\": \"text\", \"text\": message}  # Add the user-provided text input\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    # Create the input text using the processor's chat template\n",
        "    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "    # Process the inputs and move to the appropriate device\n",
        "    inputs = processor(image, input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Return a streaming generator of responses\n",
        "    return stream_response(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3CyceWSRAMZ",
        "outputId": "8f56885b-25fd-45c8-ea68-acce9409cc1d"
      },
      "outputs": [],
      "source": [
        "# prompt: Can you create a python code that takes the page_1.png file and pass the message \"Please extract the first table in csv format of the image\" and also display the results in streaming, such we can see how is generated\n",
        "from PIL import Image\n",
        "# Assuming 'page_1.png' is in the current directory or you provide the correct path\n",
        "image = Image.open(\"page_1.png\")\n",
        "example='''Table 1:\n",
        "value1,value2,value3\n",
        "\n",
        "Table 2:\n",
        "value1,value2,value3\n",
        "'''\n",
        "message = \"Please generate the csv file of all tables. You can include some rows with empty values. You can separate the tables by table_n.csv: then the table in csv. Print only the csv files. For example \"+example +\"Keep the name of original headers\"\n",
        "\n",
        "# Call the predict function with the image and message, capturing the streaming output\n",
        "full_response = \"\"\n",
        "for response in predict(message, image):\n",
        "  print(response, end=\"\", flush=True)  # Print each part of the response as it's generated\n",
        "  full_response += response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "76pLB1yrOYfx",
        "outputId": "8150a3ed-c11d-4bfa-819f-c2e8aa54dc79"
      },
      "outputs": [],
      "source": [
        "full_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvdXay8xOdos",
        "outputId": "ddb512be-167c-4283-ccb8-494f7d9ac401"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "files_list = []\n",
        "\n",
        "def extract_and_save_tables(full_response):\n",
        "    \"\"\"Extracts CSV tables from the full_response string and saves them as separate files.\"\"\"\n",
        "    current_table_name = None\n",
        "    current_table_rows = []\n",
        "\n",
        "    for line in full_response.splitlines():\n",
        "        if line.startswith(\"Table \"):\n",
        "            if current_table_name:\n",
        "                # Save the previous table\n",
        "                save_table_to_csv(current_table_name, current_table_rows)\n",
        "                files_list.append(current_table_name)  # Add file name to the list\n",
        "\n",
        "            # Extract the table number to create the filename\n",
        "            current_table_name = \"table_\" + line.split(\"Table \")[1].replace(\":\", \"\").strip() + \".csv\"\n",
        "            current_table_rows = []\n",
        "        elif current_table_name:\n",
        "            # If it's not an empty line, add it to the current table rows\n",
        "            if line.strip():\n",
        "                current_table_rows.append(line)\n",
        "\n",
        "    # Save the last table\n",
        "    if current_table_name:\n",
        "        save_table_to_csv(current_table_name, current_table_rows)\n",
        "        files_list.append(current_table_name)  # Add file name to the list\n",
        "\n",
        "def save_table_to_csv(table_name, table_rows):\n",
        "    \"\"\"Saves a table to a CSV file.\"\"\"\n",
        "    try:\n",
        "        with open(table_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "\n",
        "            # Write each row to the CSV file\n",
        "            for row in table_rows:\n",
        "                writer.writerow(row.split(\",\"))\n",
        "        print(f\"Table saved as: {table_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving table {table_name}: {e}\")\n",
        "# Run the extraction and saving process\n",
        "extract_and_save_tables(full_response)\n",
        "\n",
        "# Print the list of created CSV files\n",
        "print(\"Files created:\", files_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJlS3B3PQTmO",
        "outputId": "942b29c5-aece-4d6d-f428-b146a6d02add"
      },
      "outputs": [],
      "source": [
        "def display_first_5_rows(filename):\n",
        "  \"\"\"Displays the first 5 rows of a CSV file.\"\"\"\n",
        "  try:\n",
        "    with open(filename, 'r', encoding='utf-8') as csvfile:\n",
        "      reader = csv.reader(csvfile)\n",
        "      rows = list(reader)\n",
        "      for i in range(min(5, len(rows))):\n",
        "        print(rows[i])\n",
        "      print(\"-\" * 20)  # Separator between files\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File not found: {filename}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error reading file {filename}: {e}\")\n",
        "\n",
        "# Loop through the files in the files_list and display the first 5 rows of each\n",
        "for filename in files_list:\n",
        "  print(f\"File: {filename}\")\n",
        "  display_first_5_rows(filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5y2nxV_vF6B"
      },
      "source": [
        "# Front End Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "TTeYcy9tZv4s",
        "outputId": "497bc302-cda4-48dc-cf93-4df28888ed8d"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoProcessor, MllamaForConditionalGeneration, TextStreamer\n",
        "from PIL import Image\n",
        "import csv\n",
        "# ... (Your existing code for model loading, predict function, etc.) ...\n",
        "def process_image(image):\n",
        "    example='''Table 1:\n",
        "value1,value2,value3\n",
        "\n",
        "Table 2:\n",
        "value1,value2,value3\n",
        "'''\n",
        "    message = \"Please generate the csv file of all tables. You can include some rows with empty values. You can separate the tables by table_n.csv: then the table in csv. Print only the csv files. For example \"+example +\"Keep the name of original headers\"\n",
        "\n",
        "\n",
        "    full_response = \"\"\n",
        "    for response in predict(message, image):\n",
        "        print(response, end=\"\", flush=True)\n",
        "        full_response += response\n",
        "\n",
        "    files_list = []\n",
        "    extract_and_save_tables(full_response)\n",
        "\n",
        "    header_info = \"\"\n",
        "    for filename in files_list:\n",
        "        try:\n",
        "            with open(filename, 'r', encoding='utf-8') as csvfile:\n",
        "                reader = csv.reader(csvfile)\n",
        "                rows = list(reader)\n",
        "                if rows:\n",
        "                    header_info += f\"**{filename}:**\\n\"\n",
        "                    header_info += \", \".join(rows[0]) + \"\\n\\n\"\n",
        "        except FileNotFoundError:\n",
        "            header_info += f\"File not found: {filename}\\n\"\n",
        "        except Exception as e:\n",
        "            header_info += f\"Error reading file {filename}: {e}\\n\"\n",
        "\n",
        "    return header_info, files_list\n",
        "\n",
        "def download_files(files_list):\n",
        "    file_paths = [os.path.abspath(file) for file in files_list]\n",
        "    return gr.File.update(value=file_paths, visible=True)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        image_input = gr.Image(type=\"pil\", label=\"Upload Image\")\n",
        "        with gr.Column():\n",
        "            header_output = gr.Textbox(label=\"Headers of Extracted Tables\")\n",
        "            download_button = gr.File(label=\"Download CSV Files\", visible=False)\n",
        "    process_button = gr.Button(\"Extract Tables\")\n",
        "    process_button.click(fn=process_image, inputs=image_input, outputs=[header_output, download_button])\n",
        "    download_button.change(fn=download_files, inputs=download_button, outputs=download_button)\n",
        "\n",
        "demo.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39K4_Mc8jMVB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "312b136ce2aa42e0be5070219307576b",
            "a36fb5ca23db4948b19f57fba5cd31df",
            "d7a72b29bef6406badf8173caa28e5f5",
            "0eb94d4dbb9447eaa29599905f9b0cc3",
            "025a52897d784ca1b89b0ccc4b9e2f7b",
            "5734b4d9e9804ee7a930f1224a7f16d2",
            "5feaad20707b44f795203b9ed47a420d",
            "d7ac2074b43f492cbea1f5d71e0b0ad2",
            "5b14bc07c0cb433787aeb6d083323f67",
            "67775943ff7b4b019799df87e42dd1cf",
            "7d655ee778b844cb8cf2c37eeb3dc1e4"
          ]
        },
        "id": "phGpHa6cqk4T",
        "outputId": "29f9c169-d479-4b25-c2fe-f261329f43b4"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoProcessor, MllamaForConditionalGeneration, TextStreamer\n",
        "from PIL import Image\n",
        "import csv\n",
        "\n",
        "# Check if we're running in a Hugging Face Space and if SPACES_ZERO_GPU is enabled\n",
        "IS_SPACES_ZERO = os.environ.get(\"SPACES_ZERO_GPU\", \"0\") == \"1\"\n",
        "IS_SPACE = os.environ.get(\"SPACE_ID\", None) is not None\n",
        "IS_GDRIVE = True\n",
        "\n",
        "# Determine the device (GPU if available, else CPU)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LOW_MEMORY = os.getenv(\"LOW_MEMORY\", \"0\") == \"1\"\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Low memory mode: {LOW_MEMORY}\")\n",
        "\n",
        "# Get Hugging Face token from environment variables\n",
        "HF_TOKEN = os.environ.get('HF_TOKEN')\n",
        "\n",
        "# Define the model name\n",
        "model_name = \"Llama-3.2-11B-Vision-Instruct\"\n",
        "if IS_GDRIVE:\n",
        "    model_path = \"/content/drive/MyDrive/models/\" + model_name\n",
        "    model = MllamaForConditionalGeneration.from_pretrained(\n",
        "        model_path,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    processor = AutoProcessor.from_pretrained(model_path)\n",
        "else:\n",
        "    model_name = \"ruslanmv/\" + model_name\n",
        "    model = MllamaForConditionalGeneration.from_pretrained(\n",
        "        model_name,\n",
        "        use_auth_token=HF_TOKEN,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    processor = AutoProcessor.from_pretrained(model_name, use_auth_token=HF_TOKEN)\n",
        "\n",
        "# Tie the model weights to ensure the model is properly loaded\n",
        "if hasattr(model, \"tie_weights\"):\n",
        "    model.tie_weights()\n",
        "\n",
        "# Stream LLM response generator with minimal parameters\n",
        "def stream_response(inputs, max_new_tokens=500, temperature=0.6):\n",
        "    try:\n",
        "        streamer = TextStreamer(tokenizer=processor.tokenizer)\n",
        "        # Simplify the generation call with minimal parameters\n",
        "        generated_tokens = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=temperature,  # Only keeping temperature\n",
        "            do_sample=True,\n",
        "            streamer=streamer  # Stream responses\n",
        "        )\n",
        "        for token in generated_tokens:\n",
        "            yield processor.decode(token, skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during token generation: {e}\")\n",
        "        yield \"Error during generation.\"\n",
        "\n",
        "def predict(message, image, max_new_tokens=2000, temperature=1.0):\n",
        "    try:\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image\"},  # Specify that an image is provided\n",
        "                {\"type\": \"text\", \"text\": message}  # Add the user-provided text input\n",
        "            ]}\n",
        "        ]\n",
        "\n",
        "        input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "        inputs = processor(image, input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        return stream_response(inputs, max_new_tokens=max_new_tokens, temperature=temperature)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in predict function: {e}\")\n",
        "        return [\"Error in prediction.\"]\n",
        "\n",
        "# Add function for extracting and saving tables\n",
        "files_list = []\n",
        "\n",
        "def extract_and_save_tables(full_response):\n",
        "    current_table_name = None\n",
        "    current_table_rows = []\n",
        "    for line in full_response.splitlines():\n",
        "        if line.startswith(\"Table \"):\n",
        "            if current_table_name:\n",
        "                save_table_to_csv(current_table_name, current_table_rows)\n",
        "                files_list.append(current_table_name)\n",
        "\n",
        "            current_table_name = \"table_\" + line.split(\"Table \")[1].replace(\":\", \"\").strip() + \".csv\"\n",
        "            current_table_rows = []\n",
        "        elif current_table_name:\n",
        "            if line.strip():\n",
        "                current_table_rows.append(line)\n",
        "\n",
        "    if current_table_name:\n",
        "        save_table_to_csv(current_table_name, current_table_rows)\n",
        "        files_list.append(current_table_name)\n",
        "\n",
        "def save_table_to_csv(table_name, table_rows):\n",
        "    try:\n",
        "        with open(table_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            for row in table_rows:\n",
        "                writer.writerow(row.split(\",\"))\n",
        "        print(f\"Table saved as: {table_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving table {table_name}: {e}\")\n",
        "\n",
        "def display_first_5_rows(filename):\n",
        "    try:\n",
        "        with open(filename, 'r', encoding='utf-8') as csvfile:\n",
        "            reader = csv.reader(csvfile)\n",
        "            rows = list(reader)\n",
        "            for i in range(min(5, len(rows))):\n",
        "                print(rows[i])\n",
        "            print(\"-\" * 20)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file {filename}: {e}\")\n",
        "\n",
        "# Setting environment variable for debugging CUDA\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "HcK5hQKmkKil",
        "outputId": "8ad7daa8-4896-437c-86d2-e18ecec28c46"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import gradio as gr\n",
        "files_list = []\n",
        "def extract_and_save_tables(full_response):\n",
        "    \"\"\"Extracts CSV tables from the full_response string and saves them as separate files.\"\"\"\n",
        "    current_table_name = None\n",
        "    current_table_rows = []\n",
        "\n",
        "    for line in full_response.splitlines():\n",
        "        if line.startswith(\"Table \"):\n",
        "            if current_table_name:\n",
        "                save_table_to_csv(current_table_name, current_table_rows)\n",
        "                files_list.append(current_table_name)\n",
        "\n",
        "            # Extract the table number to create the filename\n",
        "            current_table_name = \"table_\" + line.split(\"Table \")[1].replace(\":\", \"\").strip() + \".csv\"\n",
        "            current_table_rows = []\n",
        "        elif current_table_name:\n",
        "            if line.strip():\n",
        "                current_table_rows.append(line)\n",
        "\n",
        "    if current_table_name:\n",
        "        save_table_to_csv(current_table_name, current_table_rows)\n",
        "        files_list.append(current_table_name)\n",
        "\n",
        "def save_table_to_csv(table_name, table_rows):\n",
        "    \"\"\"Saves a table to a CSV file.\"\"\"\n",
        "    try:\n",
        "        with open(table_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            for row in table_rows:\n",
        "                writer.writerow(row.split(\",\"))\n",
        "        print(f\"Table saved as: {table_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving table {table_name}: {e}\")\n",
        "\n",
        "def process_image(image):\n",
        "    example = '''Table 1:\n",
        "    header1,header2,header3\n",
        "    value1,value2,value3\n",
        "\n",
        "    Table 2:\n",
        "    value1,value2,value3\n",
        "    '''\n",
        "    message = \"Please extract the table and generate the csv. If there are more tables separate the tables using table_n.csv. Then print table in csv. Print only the csv files. Please use name of original headers of the table. For example: \" + example\n",
        "    full_response = \"\"\n",
        "\n",
        "    # Simulate the response prediction from LLM\n",
        "    # Replace this with the actual logic from your model\n",
        "    for response in predict(message, image):  # `predict` is assumed to be a generator-like function\n",
        "        print(response, end=\"\", flush=True)\n",
        "        full_response += response\n",
        "\n",
        "    extract_and_save_tables(full_response)\n",
        "\n",
        "    header_info = \"\"\n",
        "    for filename in files_list:\n",
        "        try:\n",
        "            with open(filename, 'r', encoding='utf-8') as csvfile:\n",
        "                reader = csv.reader(csvfile)\n",
        "                rows = list(reader)\n",
        "                if rows:\n",
        "                    header_info += f\"**{filename}:**\\n\"\n",
        "                    header_info += \", \".join(rows[0]) + \"\\n\\n\"\n",
        "        except FileNotFoundError:\n",
        "            header_info += f\"File not found: {filename}\\n\"\n",
        "        except Exception as e:\n",
        "            header_info += f\"Error reading file {filename}: {e}\\n\"\n",
        "\n",
        "    # Return header information and the list of file paths\n",
        "    file_paths = [os.path.abspath(file) for file in files_list]\n",
        "    return header_info, file_paths\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        image_input = gr.Image(type=\"pil\", label=\"Upload Image\")\n",
        "        with gr.Column():\n",
        "            header_output = gr.Textbox(label=\"Headers of Extracted Tables\")\n",
        "            download_button = gr.File(label=\"Download CSV Files\", file_count=\"multiple\")\n",
        "    process_button = gr.Button(\"Extract Tables\")\n",
        "    process_button.click(fn=process_image, inputs=image_input, outputs=[header_output, download_button])\n",
        "\n",
        "demo.launch(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o8rRbRqjRtK"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "025a52897d784ca1b89b0ccc4b9e2f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eb94d4dbb9447eaa29599905f9b0cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67775943ff7b4b019799df87e42dd1cf",
            "placeholder": "​",
            "style": "IPY_MODEL_7d655ee778b844cb8cf2c37eeb3dc1e4",
            "value": " 5/5 [00:04&lt;00:00,  1.24it/s]"
          }
        },
        "1955516ec46949d5b0515c5b4486c614": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b736b7c75f4c15a32c11319cf32057",
            "placeholder": "​",
            "style": "IPY_MODEL_d13d46a3a7374ab28aba00937bbe7fc7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1cb0f8ff5c7d486787fd9d9d950d0164": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "293fcf4e243d4c5c9006205240a93371": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c78f5f1933496f8e3cb53be3a67a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b12c03a02f54719b80ed75f24855e78",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cb0f8ff5c7d486787fd9d9d950d0164",
            "value": 5
          }
        },
        "312b136ce2aa42e0be5070219307576b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a36fb5ca23db4948b19f57fba5cd31df",
              "IPY_MODEL_d7a72b29bef6406badf8173caa28e5f5",
              "IPY_MODEL_0eb94d4dbb9447eaa29599905f9b0cc3"
            ],
            "layout": "IPY_MODEL_025a52897d784ca1b89b0ccc4b9e2f7b"
          }
        },
        "5040ec467bbf4a51abb864e017e08684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1955516ec46949d5b0515c5b4486c614",
              "IPY_MODEL_30c78f5f1933496f8e3cb53be3a67a45",
              "IPY_MODEL_c08e1c100fb846949141d0fe5c99c0da"
            ],
            "layout": "IPY_MODEL_9a80dc7dc36d4ff8bd811cba89b331d5"
          }
        },
        "5734b4d9e9804ee7a930f1224a7f16d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b14bc07c0cb433787aeb6d083323f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5feaad20707b44f795203b9ed47a420d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67775943ff7b4b019799df87e42dd1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d655ee778b844cb8cf2c37eeb3dc1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a80dc7dc36d4ff8bd811cba89b331d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b12c03a02f54719b80ed75f24855e78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea28926351443e89b63796f941cfa5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a36fb5ca23db4948b19f57fba5cd31df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5734b4d9e9804ee7a930f1224a7f16d2",
            "placeholder": "​",
            "style": "IPY_MODEL_5feaad20707b44f795203b9ed47a420d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a8b736b7c75f4c15a32c11319cf32057": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c08e1c100fb846949141d0fe5c99c0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_293fcf4e243d4c5c9006205240a93371",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea28926351443e89b63796f941cfa5c",
            "value": " 5/5 [01:55&lt;00:00, 18.37s/it]"
          }
        },
        "d13d46a3a7374ab28aba00937bbe7fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7a72b29bef6406badf8173caa28e5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7ac2074b43f492cbea1f5d71e0b0ad2",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b14bc07c0cb433787aeb6d083323f67",
            "value": 5
          }
        },
        "d7ac2074b43f492cbea1f5d71e0b0ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
